<div align="center"><div align="center">



# Mekhanikube ğŸ”§# Mekhanikube ğŸ”§



**Your Kubernetes AI Mechanic****Your Kubernetes AI Mechanic**



[![Docker Build](https://github.com/jorgegabrielti/mekhanikube/actions/workflows/docker-build.yml/badge.svg)](https://github.com/jorgegabrielti/mekhanikube/actions)[![Docker Build](https://github.com/jorgegabrielti/mekhanikube/actions/workflows/docker-build.yml/badge.svg)](https://github.com/jorgegabrielti/mekhanikube/actions)

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

[![Version](https://img.shields.io/badge/version-1.0.0-blue.svg)](https://github.com/jorgegabrielti/mekhanikube/releases)[![Version](https://img.shields.io/badge/version-1.0.0-blue.svg)](https://github.com/jorgegabrielti/mekhanikube/releases)

[![K8sGPT](https://img.shields.io/badge/K8sGPT-latest-brightgreen.svg)](https://github.com/k8sgpt-ai/k8sgpt)[![K8sGPT](https://img.shields.io/badge/K8sGPT-latest-brightgreen.svg)](https://github.com/k8sgpt-ai/k8sgpt)

[![Ollama](https://img.shields.io/badge/Ollama-latest-orange.svg)](https://ollama.ai/)[![Ollama](https://img.shields.io/badge/Ollama-latest-orange.svg)](https://ollama.ai/)



AI-powered Kubernetes cluster analysis using K8sGPT with local LLM (Ollama). Automatically diagnoses problems, explains causes, and suggests solutions.AnÃ¡lise inteligente de clusters Kubernetes usando K8sGPT com IA local (Ollama). Diagnostica problemas, explica causas e sugere soluÃ§Ãµes automaticamente.



[Quick Start](#-quick-start) â€¢[Quick Start](#-quick-start) â€¢

[Documentation](docs/) â€¢[Documentation](docs/) â€¢

[Contributing](CONTRIBUTING.md) â€¢[Contributing](CONTRIBUTING.md) â€¢

[Changelog](CHANGELOG.md)[Changelog](CHANGELOG.md)



</div></div>



------



## âœ¨ Features## ğŸš€ Quick Start



- ğŸ¤– **AI-Powered Analysis** - Local LLM explains Kubernetes issues in plain language### Prerequisites

- ğŸ”’ **Privacy First** - All data stays local, no external API calls

- ğŸ³ **Easy Setup** - Single command installation with Docker Compose- [Docker](https://docs.docker.com/get-docker/) and [Docker Compose](https://docs.docker.com/compose/install/)

- âš¡ **Fast Diagnostics** - Quickly identify and understand cluster problems- Active Kubernetes cluster with configured kubeconfig

- ğŸ¯ **Actionable Solutions** - Get concrete steps to fix issues- At least 8GB of free disk space for AI models

- ğŸ“¦ **No Kubernetes Modification** - Read-only cluster access

- ğŸ”„ **Multiple Models** - Support for various LLM models (Gemma, Mistral, Llama2)### Installation



## ğŸš€ Quick Start```bash

# Clone the repository

### Prerequisitesgit clone https://github.com/jorgegabrielti/mekhanikube.git

cd mekhanikube

- [Docker](https://docs.docker.com/get-docker/) and [Docker Compose](https://docs.docker.com/compose/install/)

- Active Kubernetes cluster with configured kubeconfig# (Optional) Copy and customize environment variables

- At least 8GB of free disk space for AI modelscp .env.example .env



### Installation# Complete setup: build, start services, and install AI model

make setup

```bash

# Clone the repository# Or step by step:

git clone https://github.com/jorgegabrielti/mekhanikube.gitmake build          # Build Docker images

cd mekhanikubemake up             # Start services

make install-model  # Download AI model (gemma:7b ~5GB)

# (Optional) Copy and customize environment variables```

cp .env.example .env

### Quick Analysis

# Complete setup: build, start services, and install AI model

make setup```bash

```# Analyze your cluster with AI explanations

make analyze

### Quick Analysis

# Or using docker-compose directly:

```bashdocker exec mekhanikube-k8sgpt k8sgpt analyze --explain

# Analyze your cluster with AI explanations```

make analyze

```### Makefile Commands



### Available Commands```bash

make help           # Show all available commands

```bashmake status         # Check service status

make help           # Show all available commandsmake logs           # View logs

make status         # Check service statusmake health         # Run health checks

make logs           # View logsmake analyze-pods   # Analyze only Pods

make health         # Run health checksmake test           # Run integration tests

make test           # Run integration tests```

```

## ğŸ“‹ Comandos K8sGPT

## ğŸ“‹ Usage Examples

```powershell

### Basic Analysis# Analisar cluster (sem IA)

docker exec mekhanikube-k8sgpt k8sgpt analyze

```bash

# Full cluster analysis# Analisar com explicaÃ§Ãµes da IA

make analyzedocker exec mekhanikube-k8sgpt k8sgpt analyze --explain



# Analyze specific namespace# Analisar namespace especÃ­fico

make analyze-ns NAMESPACE=kube-systemdocker exec mekhanikube-k8sgpt k8sgpt analyze -n kube-system --explain



# Analyze only Pods# Filtrar por tipo de recurso

make analyze-podsdocker exec mekhanikube-k8sgpt k8sgpt analyze --filter=Pod --explain

docker exec mekhanikube-k8sgpt k8sgpt analyze --filter=Service --explain

# Analyze only Services

make analyze-services# Listar filtros disponÃ­veis

```docker exec mekhanikube-k8sgpt k8sgpt filters list



### Model Management# Verificar configuraÃ§Ã£o

docker exec mekhanikube-k8sgpt k8sgpt auth list

```bash```

# List installed models

make list-models## ğŸ› ï¸ ConfiguraÃ§Ã£o



# Install a different model### Modelos Ollama Recomendados

make install-model MODEL=mistral

```powershell

# Switch active model# Gemma 7B (recomendado - boa qualidade)

make change-model MODEL=mistraldocker exec mekhanikube-ollama ollama pull gemma:7b

```

# Mistral (alternativa)

### Troubleshootingdocker exec mekhanikube-ollama ollama pull mistral



```bash# TinyLlama (mais rÃ¡pido, qualidade inferior)

# Check system healthdocker exec mekhanikube-ollama ollama pull tinyllama

make health```



# View logs### Trocar modelo

make logs

```powershell

# Restart services# Remover backend atual

make restartdocker exec mekhanikube-k8sgpt k8sgpt auth remove --backend localai

```

# Adicionar com novo modelo

## ğŸ› ï¸ Configurationdocker exec mekhanikube-k8sgpt k8sgpt auth add --backend localai --model mistral --baseurl http://localhost:11434/v1

docker exec mekhanikube-k8sgpt k8sgpt auth default -p localai

Mekhanikube can be configured via environment variables. Copy `.env.example` to `.env` and customize:```



```bash## ğŸ“Š Arquitetura

# AI Model Configuration

OLLAMA_MODEL=gemma:7b```

OLLAMA_PORT=11434â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚   Kubernetes    â”‚

# Kubernetes Configurationâ”‚     Cluster     â”‚

KUBECONFIG_PATH=C:/Users/${USERNAME}/.kube/configâ”‚   (em VM/Host)  â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# Container Configuration         â”‚ kubeconfig (montado em /root/.kube/)

CONTAINER_NAME_OLLAMA=mekhanikube-ollama         â”‚

CONTAINER_NAME_K8SGPT=mekhanikube-k8sgpt    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

```    â”‚  k8sgpt container â”‚

    â”‚  - Ajusta config  â”‚

### Recommended Models    â”‚    automaticamenteâ”‚

    â”‚  - Roda anÃ¡lises  â”‚

| Model | Size | Speed | Quality | Best For |    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

|-------|------|-------|---------|----------|             â”‚ API calls (http://localhost:11434/v1)

| **gemma:7b** | 4.8GB | Medium | Good | General use (recommended) |             â”‚

| **mistral** | 4.1GB | Medium | Good | Detailed explanations |    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

| **tinyllama** | 1.1GB | Fast | Basic | Quick scans |    â”‚ ollama container  â”‚

| **llama2:13b** | 7.4GB | Slow | Excellent | Best quality |    â”‚  - Gemma:7b model â”‚

    â”‚  - Gera explicaÃ§Ãµesâ”‚

## ğŸ“– Documentation    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

- ğŸ“– **[Architecture](docs/ARCHITECTURE.md)** - System design and components

- ğŸ”§ **[Troubleshooting](docs/TROUBLESHOOTING.md)** - Common issues and solutions## ğŸ”§ Troubleshooting

- â“ **[FAQ](docs/FAQ.md)** - Frequently asked questions

- ğŸ“‚ **[Project Structure](docs/PROJECT_STRUCTURE.md)** - File organization### K8sGPT nÃ£o consegue acessar cluster

- ğŸ¤ **[Contributing](CONTRIBUTING.md)** - How to contribute

- ğŸ”’ **[Security](SECURITY.md)** - Security policy```powershell

- ğŸ“ **[Changelog](CHANGELOG.md)** - Version history# Verificar se kubeconfig estÃ¡ montado

docker exec mekhanikube-k8sgpt ls -la /root/.kube/

## ğŸ” How It Works

# Verificar se config_mod foi criado pelo entrypoint

1. **Automatic Configuration**: Container startup script adjusts kubeconfig and configures K8sGPT backenddocker exec mekhanikube-k8sgpt cat /root/.kube/config_mod

2. **Cluster Analysis**: K8sGPT scans your Kubernetes cluster and detects issues

3. **AI Explanation**: For each issue, K8sGPT sends context to Ollama for analysis# Testar conexÃ£o manual

4. **Results**: Clear, actionable output with explanations and solutionsdocker exec mekhanikube-k8sgpt kubectl get nodes

```

## ğŸ—ï¸ Architecture

### Ollama nÃ£o responde

```

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”```powershell

â”‚                      Host Machine                            â”‚# Ver logs

â”‚                                                              â”‚docker logs mekhanikube-ollama

â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚

â”‚  â”‚  Kubernetes Clusterâ”‚         â”‚   Docker Host      â”‚     â”‚# Verificar modelos instalados

â”‚  â”‚  - Pods            â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”¤                    â”‚     â”‚docker exec mekhanikube-ollama ollama list

â”‚  â”‚  - Services        â”‚ K8s API â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚     â”‚

â”‚  â”‚  - Deployments     â”‚         â”‚  â”‚   Ollama     â”‚ â”‚     â”‚# Testar API

â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  â”‚   Container  â”‚ â”‚     â”‚Invoke-RestMethod -Uri http://localhost:11434/v1/models | ConvertTo-Json

â”‚           â–²                      â”‚  â”‚  - Gemma:7b  â”‚ â”‚     â”‚

â”‚           â”‚ kubeconfig           â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚     â”‚# Baixar modelo novamente

â”‚           â”‚                      â”‚         â”‚ HTTP    â”‚     â”‚docker exec mekhanikube-ollama ollama pull gemma:7b

â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â” â”‚     â”‚```

â”‚  â”‚  ~/.kube/config â”‚             â”‚  â”‚   K8sGPT     â”‚ â”‚     â”‚

â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚  â”‚   Container  â”‚ â”‚     â”‚### Container k8sgpt nÃ£o inicia

â”‚                                  â”‚  â”‚  - Analysis  â”‚ â”‚     â”‚

â”‚                                  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚     â”‚```powershell

â”‚                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚# Ver logs

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜docker logs mekhanikube-k8sgpt

```

# Reconstruir imagem

## ğŸ¤ Contributingdocker-compose build k8sgpt

docker-compose up -d k8sgpt

Contributions are welcome! Please read our [Contributing Guidelines](CONTRIBUTING.md) and [Code of Conduct](CODE_OF_CONDUCT.md).```



1. Fork the repository## ğŸ“š Recursos

2. Create a feature branch: `git checkout -b feature/amazing-feature`

3. Make your changes and test: `make test`- [K8sGPT Docs](https://docs.k8sgpt.ai/)

4. Commit: `git commit -m 'Add amazing feature'`- [Ollama Models](https://ollama.com/library)

5. Push: `git push origin feature/amazing-feature`- [K8sGPT GitHub](https://github.com/k8sgpt-ai/k8sgpt)

6. Open a Pull Request

## ï¿½ Documentation

## ğŸ“ License

- ğŸ“– **[Architecture](docs/ARCHITECTURE.md)** - System design and components

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.- ğŸ”§ **[Troubleshooting](docs/TROUBLESHOOTING.md)** - Common issues and solutions

- â“ **[FAQ](docs/FAQ.md)** - Frequently asked questions

## ğŸ™ Acknowledgments- ğŸ“‚ **[Project Structure](docs/PROJECT_STRUCTURE.md)** - File organization

- ğŸ¤ **[Contributing](CONTRIBUTING.md)** - How to contribute

- [K8sGPT](https://github.com/k8sgpt-ai/k8sgpt) - AI-powered Kubernetes diagnostics- ğŸ”’ **[Security](SECURITY.md)** - Security policy

- [Ollama](https://ollama.ai/) - Local LLM inference- ğŸ“ **[Changelog](CHANGELOG.md)** - Version history

- All contributors who help improve this project

## ğŸ” How It Works

## ğŸ“¬ Contact & Support

1. **Automatic Configuration**: The k8sgpt container runs `/entrypoint.sh` at startup:

- ğŸ› **Bug Reports**: [GitHub Issues](https://github.com/jorgegabrielti/mekhanikube/issues)   - Copies the mounted kubeconfig from `/root/.kube/config`

- ğŸ’¡ **Feature Requests**: [GitHub Issues](https://github.com/jorgegabrielti/mekhanikube/issues)   - Replaces `127.0.0.1` with `host.docker.internal` for container networking

- ğŸ’¬ **Discussions**: [GitHub Discussions](https://github.com/jorgegabrielti/mekhanikube/discussions)   - Saves modified config to `/root/.kube/config_mod`

   - Sets `KUBECONFIG=/root/.kube/config_mod`

---   - Configures K8sGPT backend with Ollama



<div align="center">2. **Cluster Analysis**: K8sGPT scans your Kubernetes cluster:

   - Detects issues across Pods, Services, Deployments, etc.

Made with â¤ï¸ for the Kubernetes community   - Identifies misconfigurations and errors

   - Collects relevant context

**[â¬† Back to Top](#mekhanikube-)**

3. **AI Explanation**: For each issue found:

</div>   - K8sGPT sends problem context to Ollama

   - LLM generates human-readable explanation
   - Suggests potential solutions

4. **Results**: Clear, actionable output with:
   - Problem description
   - AI-generated explanation
   - Suggested remediation steps

2. **AnÃ¡lise**: K8sGPT escaneia o cluster e identifica problemas (ConfigMaps nÃ£o usados, Pods com erro, etc)

3. **ExplicaÃ§Ã£o**: Quando usa `--explain`, K8sGPT envia o problema para Ollama via API REST

4. **Resposta**: Ollama processa com o modelo gemma:7b e retorna explicaÃ§Ã£o + soluÃ§Ã£o



Se vocÃª jÃ¡ tem Ollama rodando:export OLLAMA_MODEL=mistral



```powershell```2. Inicie o Ollama:

# O programa detecta automaticamente

.\kube-ai.exe```bash

```

## Usodocker-compose up -d

**Nota:** Ollama Ã© significativamente mais lento (1-2 minutos por scan).

```

---

```bash

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

# Iniciar chat interativo3. Instale o modelo Mistral:

### VariÃ¡veis de Ambiente

./kube-ai```bash

```powershell

# ForÃ§ar uso de LocalAIdocker exec -it ollama ollama pull mistral

$env:LLM_PROVIDER="localai"

$env:LOCALAI_URL="http://localhost:8080"# Comandos disponÃ­veis:```

$env:LOCALAI_MODEL="phi-2"

# scan    - Escanear cluster em busca de problemas

# ForÃ§ar uso de Ollama

$env:LLM_PROVIDER="ollama"# exit    - Sair do chat4. Compile e instale a CLI:

$env:OLLAMA_URL="http://localhost:11434"

$env:OLLAMA_MODEL="mistral"# qualquer texto - Fazer perguntas sobre Kubernetes```bash

```

```go install ./cmd/kube-ai

---

```

## ğŸ“Š ComparaÃ§Ã£o de Performance

## Exemplos

| Provider | Modelo    | Tempo/Scan | Qualidade | RAM   |

|----------|-----------|------------|-----------|-------|## Uso

| LocalAI  | phi-2     | ~5-10s     | â­â­â­â­    | 2GB   |

| Ollama   | mistral   | ~60-120s   | â­â­â­â­â­  | 4GB   |```

| Ollama   | tinyllama | ~30-60s    | â­â­â­     | 2GB   |

> scanSimplesmente execute:

**RecomendaÃ§Ã£o:** Use LocalAI com phi-2 para melhor balance entre velocidade e qualidade.

ğŸ” Escaneando cluster...```bash

---

ğŸ¤– Analisando 2 problemas encontrados...kube-ai

## ğŸ› ï¸ Troubleshooting

```

### LocalAI nÃ£o inicia

> O que Ã© um CrashLoopBackOff?

```powershell

# Verifique se o modelo foi baixadoğŸ¤– CrashLoopBackOff indica que um container estÃ¡ falhando...A ferramenta irÃ¡:

dir .\models\

1. Conectar ao seu cluster Kubernetes

# Verifique logs do container

docker-compose logs localai> Como debugar um pod?2. Procurar por pods com problemas



# Reinicie o serviÃ§oğŸ¤– Use kubectl describe pod <name> para ver eventos...3. Coletar informaÃ§Ãµes detalhadas

docker-compose restart

``````4. Usar IA local para analisar e sugerir soluÃ§Ãµes



### Scan muito lento

Se nenhum problema for encontrado, vocÃª verÃ¡:

- âœ… **SoluÃ§Ã£o:** Use LocalAI em vez de Ollama```

- Execute: `.\download-model.ps1` e `docker-compose up -d`âœ… Cluster saudÃ¡vel

```

### Erro de conexÃ£o com Kubernetes

Se problemas forem encontrados, vocÃª receberÃ¡ uma anÃ¡lise detalhada com:

```powershell- Causa provÃ¡vel do problema

# Verifique se o cluster estÃ¡ acessÃ­vel- Como resolver o problema

kubectl cluster-info- Como prevenir que aconteÃ§a novamente

go mod init kube-ai

# Verifique o contexto atualgo get k8s.io/client-go

kubectl config current-contextgo build -o kube-ai ./cmd/kube-ai

``````



---## Uso



## ğŸ“¦ Requisitos```bash

./kube-ai

- **Go:** 1.21 ou superior```

- **Docker Desktop:** Com Kubernetes habilitado

- **RAM:** 4GB disponÃ­vel## Estrutura do Projeto

- **Disco:** 2GB para modelo Phi-2

```

---kube-ai/

 â”œâ”€â”€ cmd/

## ğŸ—ï¸ Arquitetura â”‚    â””â”€â”€ kube-ai/        # main.go, parsing de comandos CLI

 â”œâ”€â”€ internal/

``` â”‚    â”œâ”€â”€ k8s/            # conexÃ£o + scanner

kube-ai/ â”‚    â”‚    â”œâ”€â”€ connect.go

â”œâ”€â”€ cmd/kube-ai/          # CLI principal â”‚    â”‚    â””â”€â”€ scan.go

â”œâ”€â”€ internal/ â”‚    â”œâ”€â”€ llm/            # integraÃ§Ã£o com ollama

â”‚   â”œâ”€â”€ k8s/             # Cliente Kubernetes â”‚    â”‚    â””â”€â”€ ollama.go

â”‚   â””â”€â”€ llm/             # Cliente LLM (LocalAI/Ollama) â”‚    â””â”€â”€ explain/        # heurÃ­sticas e montagem de prompts

â”œâ”€â”€ models/              # Modelos de IA â”‚         â””â”€â”€ explain.go

â”œâ”€â”€ docker-compose.yml   # LocalAI setup â”œâ”€â”€ go.mod

â””â”€â”€ download-model.ps1   # Script para baixar Phi-2 â””â”€â”€ README.md

``````

---

## ğŸ“ LicenÃ§a

MIT


